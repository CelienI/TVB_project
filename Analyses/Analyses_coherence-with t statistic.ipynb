{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "average-tooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "%pylab nbagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "minute-change",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab nbagg\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import scipy \n",
    "import scipy.fftpack\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy import signal\n",
    "\n",
    "from scipy import stats\n",
    "from netchos import circular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acting-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/celie/OneDrive - ugentbe/NOG NODIG/2de master/Masterproef/Datasets/All_freqs\")\n",
    "mydir = \"C:/Users/celie/OneDrive - ugentbe/NOG NODIG/2de master/Masterproef/Datasets/All_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "representative-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "filename = mydir + \"/Health_ROI_order.csv\"\n",
    "ROI_H = pd.read_csv(filename)\n",
    "ROI_H = np.array(ROI_H)\n",
    "\n",
    "filename = mydir + \"/Depressed_ROI_order.csv\"\n",
    "ROID = pd.read_csv(filename)\n",
    "ROI_D = np.array(ROID)\n",
    "\n",
    "filename = mydir + \"/HF_ROI_order.csv\"\n",
    "ROIHF = pd.read_csv(filename)\n",
    "ROI_HF = np.array(ROIHF)\n",
    "\n",
    "filename = mydir + \"/LF_ROI_order.csv\"\n",
    "ROILF = pd.read_csv(filename)\n",
    "ROI_LF = np.array(ROILF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polished-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = mydir + \"/HF_coh_total_hstacked_alfa100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     HFall = f['data'][:]\n",
    "        \n",
    "\n",
    "filename = mydir + \"/HF_coh_total_hstacked_8100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     HF_8 = f['data'][:]\n",
    "        \n",
    "filename = mydir + \"/HF_coh_total_hstacked_9100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     HF_9 = f['data'][:]\n",
    "\n",
    "filename = mydir + \"/HF_coh_total_hstacked_10100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     HF_10 = f['data'][:]\n",
    "        \n",
    "filename = mydir + \"/HF_coh_total_hstacked_11100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     HF_11 = f['data'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "technological-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = mydir + \"/LF_coh_total_hstacked_alfa100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     LFall = f['data'][:]\n",
    "        \n",
    "\n",
    "filename = mydir + \"/LF_coh_total_hstacked_8100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     LF_8 = f['data'][:]\n",
    "        \n",
    "filename = mydir + \"/LF_coh_total_hstacked_9100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     LF_9 = f['data'][:]\n",
    "\n",
    "filename = mydir + \"/LF_coh_total_hstacked_10100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     LF_10 = f['data'][:]\n",
    "        \n",
    "filename = mydir + \"/LF_coh_total_hstacked_11100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     LF_11 = f['data'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pretty-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = mydir + \"/Health_coh_total_hstacked_alfa100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     Healthall = f['data'][:]\n",
    "        \n",
    "\n",
    "filename = mydir + \"/Health_coh_total_hstacked_8100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     Health_8 = f['data'][:]\n",
    "        \n",
    "filename = mydir + \"/Health_coh_total_hstacked_9100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     Health_9 = f['data'][:]\n",
    "\n",
    "filename = mydir + \"/Health_coh_total_hstacked_10100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     Health_10 = f['data'][:]\n",
    "        \n",
    "filename = mydir + \"/Health_coh_total_hstacked_11100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     Health_11 = f['data'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "curious-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = mydir + \"/Depressed_coh_total_hstacked_alfa100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     Deprall = f['data'][:]\n",
    "        \n",
    "\n",
    "filename = mydir + \"/Depressed_coh_total_hstacked_8100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     Depr_8 = f['data'][:]\n",
    "        \n",
    "filename = mydir + \"/Depressed_coh_total_hstacked_9100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     Depr_9 = f['data'][:]\n",
    "\n",
    "filename = mydir + \"/Depressed_coh_total_hstacked_10100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     Depr_10 = f['data'][:]\n",
    "        \n",
    "filename = mydir + \"/Depressed_coh_total_hstacked_11100.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     Depr_11 = f['data'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "automatic-sustainability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378, 1100)\n",
      "(378, 300)\n",
      "(378, 200)\n",
      "(378, 300)\n",
      "(378, 300)\n",
      "(378, 1100)\n",
      "(378, 300)\n",
      "(378, 200)\n",
      "(378, 300)\n",
      "(378, 300)\n",
      "(378, 1100)\n",
      "(378, 300)\n",
      "(378, 200)\n",
      "(378, 300)\n",
      "(378, 300)\n",
      "(378, 1100)\n",
      "(378, 300)\n",
      "(378, 200)\n",
      "(378, 300)\n",
      "(378, 300)\n"
     ]
    }
   ],
   "source": [
    "print(shape(HFall))\n",
    "print(shape(HF_8))\n",
    "print(shape(HF_9))\n",
    "print(shape(HF_10))\n",
    "print(shape(HF_11))\n",
    "\n",
    "print(shape(LFall))\n",
    "print(shape(LF_8))\n",
    "print(shape(LF_9))\n",
    "print(shape(LF_10))\n",
    "print(shape(LF_11))\n",
    "\n",
    "print(shape(Healthall))\n",
    "print(shape(Health_8))\n",
    "print(shape(Health_9))\n",
    "print(shape(Health_10))\n",
    "print(shape(Health_11))\n",
    "\n",
    "print(shape(Deprall))\n",
    "print(shape(Depr_8))\n",
    "print(shape(Depr_9))\n",
    "print(shape(Depr_10))\n",
    "print(shape(Depr_11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incident-darwin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378, 4)\n",
      "(378, 4)\n",
      "(378, 4)\n",
      "(378, 4)\n"
     ]
    }
   ],
   "source": [
    "print(shape(ROI_D))\n",
    "print(shape(ROI_H))\n",
    "print(shape(ROI_HF))\n",
    "print(shape(ROI_LF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "encouraging-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.vectors import FloatVector\n",
    "\n",
    "stats2 = importr('stats')\n",
    "def EFsize(c0, c1):\n",
    "    d = (mean(c0) - mean(c1)) / (sqrt((statistics.stdev(c0) ** 2 + statistics.stdev(c1) ** 2) / 2))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stuffed-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydir = \"C:/Users/celie/OneDrive - ugentbe/NOG NODIG/2de master/Masterproef/Datasets/All_results/Coherence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "alpine-intersection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "#Calculate coherence over entire alpha band \n",
    "\n",
    "c1 = np.repeat(\"\", 1)\n",
    "c2 = np.repeat(\"\",1)\n",
    "\n",
    "n_pairs = len(ROI_D)\n",
    "sig_count = False \n",
    "base = numpy.zeros(shape=(1,26)) \n",
    "#ROI1, ROI2, mean (4 times), sd (4 times), p value (H_D, H_HF, H_LF, D_HF, D_LF, HF_LF), 6 statistics\n",
    "sign_array = np.column_stack([c1, c2, base])\n",
    "sign_array_tot= np.column_stack([c1, c2, base])\n",
    "\n",
    "p_array = np.column_stack([c1, c2,base])\n",
    "p_array_tot= np.column_stack([c1, c2, base])\n",
    "\n",
    "Depr = Deprall\n",
    "Health = Healthall\n",
    "HF = HFall\n",
    "LF = LFall\n",
    "\n",
    "for i in range(n_pairs):\n",
    "    data_dep = Depr[i]\n",
    "    data_health = Health[i]\n",
    "    data_HF = HF[i]\n",
    "    data_LF = LF[i]\n",
    "    \n",
    "    ROI1 = ROI_D[i][0]\n",
    "    ROI2 = ROI_D[i][1]\n",
    "    \n",
    "    #p_values\n",
    "    p_H_D = stats.ttest_ind(data_dep, data_health).pvalue\n",
    "    p_H_LF = stats.ttest_ind(data_LF, data_health).pvalue\n",
    "    p_H_HF = stats.ttest_ind(data_HF, data_health).pvalue\n",
    "    p_D_LF = stats.ttest_ind(data_dep, data_LF).pvalue\n",
    "    p_D_HF = stats.ttest_ind(data_dep, data_HF).pvalue\n",
    "    p_HF_LF = stats.ttest_ind(data_LF, data_HF).pvalue\n",
    "    \n",
    "    #t_stats\n",
    "    t_H_D = stats.ttest_ind(data_dep, data_health).statistic\n",
    "    t_H_LF = stats.ttest_ind(data_LF, data_health).statistic\n",
    "    t_H_HF = stats.ttest_ind(data_HF, data_health).statistic\n",
    "    t_D_LF = stats.ttest_ind(data_dep, data_LF).statistic\n",
    "    t_D_HF = stats.ttest_ind(data_dep, data_HF).statistic\n",
    "    t_HF_LF = stats.ttest_ind(data_LF, data_HF).statistic\n",
    "    \n",
    "    #Effect sizes\n",
    "    EF_H_D = EFsize(data_dep, data_health)\n",
    "    EF_H_LF = EFsize(data_LF, data_health)\n",
    "    EF_H_HF = EFsize(data_HF, data_health)\n",
    "    EF_D_LF = EFsize(data_dep, data_LF)\n",
    "    EF_D_HF = EFsize(data_dep, data_HF)\n",
    "    EF_HF_LF = EFsize(data_LF, data_HF)\n",
    "    \n",
    "    #make general p_value output (for all comparisons)\n",
    "    p_array[0][0] = str(ROI1)\n",
    "    p_array[0][1] = str(ROI2)\n",
    "    p_array[0][2] = mean(data_dep)\n",
    "    p_array[0][3] = mean(data_health)\n",
    "    p_array[0][4] = mean(data_HF)\n",
    "    p_array[0][5] = mean(data_LF)\n",
    "    p_array[0][6] = std(data_dep)\n",
    "    p_array[0][7] = std(data_health)\n",
    "    p_array[0][8] = std(data_HF)\n",
    "    p_array[0][9] = std(data_LF)\n",
    "    p_array[0][10] = p_H_D\n",
    "    p_array[0][11] = p_H_LF\n",
    "    p_array[0][12] = p_H_HF\n",
    "    p_array[0][13] = p_D_LF\n",
    "    p_array[0][14] = p_D_HF\n",
    "    p_array[0][15] = p_HF_LF\n",
    "    p_array[0][16] = EF_H_D\n",
    "    p_array[0][17] = EF_H_LF\n",
    "    p_array[0][18] = EF_H_HF\n",
    "    p_array[0][19] = EF_D_LF\n",
    "    p_array[0][20] = EF_D_HF\n",
    "    p_array[0][21] = EF_HF_LF\n",
    "    p_array[0][22] = t_H_D\n",
    "    p_array[0][23] = t_H_LF\n",
    "    p_array[0][24] = t_H_HF\n",
    "    p_array[0][25] = t_D_LF\n",
    "    p_array[0][26] = t_D_HF\n",
    "    p_array[0][27] = t_HF_LF\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #if any of p-values is significant: store these regions and all p-values corresponding in the significant matrix\n",
    "    if p_H_D <= 0.05 or p_H_LF <= 0.05 or p_H_HF <= 0.05 or p_D_LF <= 0.05 or p_D_HF <= 0.05 or p_HF_LF <= 0.05:\n",
    "        sign_array[0][0] = str(ROI1)\n",
    "        sign_array[0][1] = str(ROI2)\n",
    "        sign_array[0][2] = mean(data_dep)\n",
    "        sign_array[0][3] = mean(data_health)\n",
    "        sign_array[0][4] = mean(data_HF)\n",
    "        sign_array[0][5] = mean(data_LF)\n",
    "        sign_array[0][6] = std(data_dep)\n",
    "        sign_array[0][7] = std(data_health)\n",
    "        sign_array[0][8] = std(data_HF)\n",
    "        sign_array[0][9] = std(data_LF)\n",
    "        sign_array[0][10] = p_H_D\n",
    "        sign_array[0][11] = p_H_LF\n",
    "        sign_array[0][12] = p_H_HF\n",
    "        sign_array[0][13] = p_D_LF\n",
    "        sign_array[0][14] = p_D_HF\n",
    "        sign_array[0][15] = p_HF_LF\n",
    "        sign_array[0][16] = EF_H_D\n",
    "        sign_array[0][17] = EF_H_LF\n",
    "        sign_array[0][18] = EF_H_HF\n",
    "        sign_array[0][19] = EF_D_LF\n",
    "        sign_array[0][20] = EF_D_HF\n",
    "        sign_array[0][21] = EF_HF_LF\n",
    "        sign_array[0][22] = t_H_D\n",
    "        sign_array[0][23] = t_H_LF\n",
    "        sign_array[0][24] = t_H_HF\n",
    "        sign_array[0][25] = t_D_LF\n",
    "        sign_array[0][26] = t_D_HF\n",
    "        sign_array[0][27] = t_HF_LF\n",
    "        \n",
    "        if sig_count == False :\n",
    "            sign_array_tot = sign_array\n",
    "            sig_count = True \n",
    "        else:\n",
    "            tupley = (sign_array_tot, sign_array)\n",
    "            sign_array_tot = np.vstack(tupley)\n",
    " \n",
    "    \n",
    "    if i == 0:\n",
    "        p_array_tot = p_array\n",
    "    else:\n",
    "        tuplex = (p_array_tot, p_array)\n",
    "        p_array_tot = np.vstack(tuplex)\n",
    "\n",
    "        \n",
    "#calculate adjusted p-values for all values\n",
    "\n",
    "p_array_tot_corrected = np.copy(p_array_tot)\n",
    "\n",
    "pHD = p_array_tot[:,10] #p values between depressed and healthy\n",
    "pH_HF = p_array_tot[:,11]\n",
    "pH_LF = p_array_tot[:,12]\n",
    "pD_HF =p_array_tot[:,13]\n",
    "pD_LF =p_array_tot[:,14]\n",
    "pHF_LF=p_array_tot[:,15]\n",
    "\n",
    "pHD = pHD.reshape(378,1)\n",
    "pH_HF = pH_HF.reshape(378,1)\n",
    "pH_LF = pH_LF.reshape(378,1)\n",
    "pD_HF = pD_HF.reshape(378,1)\n",
    "pD_LF= pD_LF.reshape(378,1)\n",
    "pHF_LF= pHF_LF.reshape(378,1)\n",
    "\n",
    "p_adjust_H_D = stats2.p_adjust(FloatVector(pHD), method = 'holm')\n",
    "p_adjust_H_HF = stats2.p_adjust(FloatVector(pH_HF), method = 'holm')\n",
    "p_adjust_H_LF = stats2.p_adjust(FloatVector(pH_LF), method = 'holm')\n",
    "p_adjust_D_HF = stats2.p_adjust(FloatVector(pD_HF), method = 'holm')\n",
    "p_adjust_D_LF = stats2.p_adjust(FloatVector(pD_LF), method = 'holm')\n",
    "p_adjust_LH_HF = stats2.p_adjust(FloatVector(pHF_LF), method = 'holm')    \n",
    "        \n",
    "p_array_tot_corrected[:,10] = p_adjust_H_D \n",
    "p_array_tot_corrected[:,11] =p_adjust_H_HF\n",
    "p_array_tot_corrected[:,12] = p_adjust_H_LF\n",
    "p_array_tot_corrected[:,13] = p_adjust_D_HF\n",
    "p_array_tot_corrected[:,14] = p_adjust_D_LF\n",
    "p_array_tot_corrected[:,15] =p_adjust_LH_HF   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"ok\")     \n",
    "file_name = mydir + \"/sign_coherence_uncorrected_alfa.csv\"\n",
    "outcome = pd.DataFrame.from_records(sign_array_tot)\n",
    "outcome.columns = [\"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"p HD\",\n",
    "                  \"p H_LF\", \"p H_HF\",\"p D_LF\", \"p D_HF\",'p_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                  \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF']\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)\n",
    "        \n",
    "tuple = (p_array_tot_corrected, p_array_tot)\n",
    "array_complete = np.hstack(tuple)\n",
    "\n",
    "file_name = mydir + \"/p-values_coherence_EF_corrected_alfa_withT.csv\"\n",
    "outcome = pd.DataFrame.from_records(array_complete)\n",
    "outcome.columns = [\"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"padj HD\",\n",
    "                  \"padj H_LF\", \"padj H_HF\",\"padj D_LF\", \"padj D_HF\",'padj_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                   \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF',\n",
    "                  \"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"p HD\",\n",
    "                  \"p H_LF\", \"p H_HF\",\"p D_LF\", \"p D_HF\",'p_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                  \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF']\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "approximate-beauty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 56)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(array_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-martial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "speaking-chair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "#Calculate coherence over lowest alpha band (8-9Hz)\n",
    "\n",
    "c1 = np.repeat(\"\", 1)\n",
    "c2 = np.repeat(\"\",1)\n",
    "\n",
    "n_pairs = len(ROI_D)\n",
    "sig_count = False \n",
    "base = numpy.zeros(shape=(1,26)) \n",
    "#ROI1, ROI2, mean (4 times), sd (4 times), p value (H_D, H_HF, H_LF, D_HF, D_LF, HF_LF)\n",
    "sign_array = np.column_stack([c1, c2, base])\n",
    "sign_array_tot= np.column_stack([c1, c2, base])\n",
    "\n",
    "p_array = np.column_stack([c1, c2,base])\n",
    "p_array_tot= np.column_stack([c1, c2, base])\n",
    "\n",
    "Depr = Depr_8\n",
    "Health = Health_8\n",
    "HF = HF_8\n",
    "LF = LF_8\n",
    "\n",
    "for i in range(n_pairs):\n",
    "    data_dep = Depr[i]\n",
    "    data_health = Health[i]\n",
    "    data_HF = HF[i]\n",
    "    data_LF = LF[i]\n",
    "    \n",
    "    ROI1 = ROI_D[i][0]\n",
    "    ROI2 = ROI_D[i][1]\n",
    "    \n",
    "    #p_values\n",
    "    p_H_D = stats.ttest_ind(data_dep, data_health).pvalue\n",
    "    p_H_LF = stats.ttest_ind(data_LF, data_health).pvalue\n",
    "    p_H_HF = stats.ttest_ind(data_HF, data_health).pvalue\n",
    "    p_D_LF = stats.ttest_ind(data_dep, data_LF).pvalue\n",
    "    p_D_HF = stats.ttest_ind(data_dep, data_HF).pvalue\n",
    "    p_HF_LF = stats.ttest_ind(data_LF, data_HF).pvalue\n",
    "    \n",
    "    #t_stats\n",
    "    t_H_D = stats.ttest_ind(data_dep, data_health).statistic\n",
    "    t_H_LF = stats.ttest_ind(data_LF, data_health).statistic\n",
    "    t_H_HF = stats.ttest_ind(data_HF, data_health).statistic\n",
    "    t_D_LF = stats.ttest_ind(data_dep, data_LF).statistic\n",
    "    t_D_HF = stats.ttest_ind(data_dep, data_HF).statistic\n",
    "    t_HF_LF = stats.ttest_ind(data_LF, data_HF).statistic\n",
    "    \n",
    "    #Effect sizes\n",
    "    EF_H_D = EFsize(data_dep, data_health)\n",
    "    EF_H_LF = EFsize(data_LF, data_health)\n",
    "    EF_H_HF = EFsize(data_HF, data_health)\n",
    "    EF_D_LF = EFsize(data_dep, data_LF)\n",
    "    EF_D_HF = EFsize(data_dep, data_HF)\n",
    "    EF_HF_LF = EFsize(data_LF, data_HF)\n",
    "    \n",
    "    #make general p_value output (for all comparisons)\n",
    "    p_array[0][0] = str(ROI1)\n",
    "    p_array[0][1] = str(ROI2)\n",
    "    p_array[0][2] = mean(data_dep)\n",
    "    p_array[0][3] = mean(data_health)\n",
    "    p_array[0][4] = mean(data_HF)\n",
    "    p_array[0][5] = mean(data_LF)\n",
    "    p_array[0][6] = std(data_dep)\n",
    "    p_array[0][7] = std(data_health)\n",
    "    p_array[0][8] = std(data_HF)\n",
    "    p_array[0][9] = std(data_LF)\n",
    "    p_array[0][10] = p_H_D\n",
    "    p_array[0][11] = p_H_LF\n",
    "    p_array[0][12] = p_H_HF\n",
    "    p_array[0][13] = p_D_LF\n",
    "    p_array[0][14] = p_D_HF\n",
    "    p_array[0][15] = p_HF_LF\n",
    "    p_array[0][16] = EF_H_D\n",
    "    p_array[0][17] = EF_H_LF\n",
    "    p_array[0][18] = EF_H_HF\n",
    "    p_array[0][19] = EF_D_LF\n",
    "    p_array[0][20] = EF_D_HF\n",
    "    p_array[0][21] = EF_HF_LF\n",
    "    p_array[0][22] = t_H_D\n",
    "    p_array[0][23] = t_H_LF\n",
    "    p_array[0][24] = t_H_HF\n",
    "    p_array[0][25] = t_D_LF\n",
    "    p_array[0][26] = t_D_HF\n",
    "    p_array[0][27] = t_HF_LF\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #if any of p-values is significant: store these regions and all p-values corresponding in the significant matrix\n",
    "    if p_H_D <= 0.05 or p_H_LF <= 0.05 or p_H_HF <= 0.05 or p_D_LF <= 0.05 or p_D_HF <= 0.05 or p_HF_LF <= 0.05:\n",
    "        sign_array[0][0] = str(ROI1)\n",
    "        sign_array[0][1] = str(ROI2)\n",
    "        sign_array[0][2] = mean(data_dep)\n",
    "        sign_array[0][3] = mean(data_health)\n",
    "        sign_array[0][4] = mean(data_HF)\n",
    "        sign_array[0][5] = mean(data_LF)\n",
    "        sign_array[0][6] = std(data_dep)\n",
    "        sign_array[0][7] = std(data_health)\n",
    "        sign_array[0][8] = std(data_HF)\n",
    "        sign_array[0][9] = std(data_LF)\n",
    "        sign_array[0][10] = p_H_D\n",
    "        sign_array[0][11] = p_H_LF\n",
    "        sign_array[0][12] = p_H_HF\n",
    "        sign_array[0][13] = p_D_LF\n",
    "        sign_array[0][14] = p_D_HF\n",
    "        sign_array[0][15] = p_HF_LF\n",
    "        sign_array[0][16] = EF_H_D\n",
    "        sign_array[0][17] = EF_H_LF\n",
    "        sign_array[0][18] = EF_H_HF\n",
    "        sign_array[0][19] = EF_D_LF\n",
    "        sign_array[0][20] = EF_D_HF\n",
    "        sign_array[0][21] = EF_HF_LF\n",
    "        sign_array[0][22] = t_H_D\n",
    "        sign_array[0][23] = t_H_LF\n",
    "        sign_array[0][24] = t_H_HF\n",
    "        sign_array[0][25] = t_D_LF\n",
    "        sign_array[0][26] = t_D_HF\n",
    "        sign_array[0][27] = t_HF_LF\n",
    "        \n",
    "        if sig_count == False :\n",
    "            sign_array_tot = sign_array\n",
    "            sig_count = True \n",
    "        else:\n",
    "            tupley = (sign_array_tot, sign_array)\n",
    "            sign_array_tot = np.vstack(tupley)\n",
    " \n",
    "    \n",
    "    if i == 0:\n",
    "        p_array_tot = p_array\n",
    "    else:\n",
    "        tuplex = (p_array_tot, p_array)\n",
    "        p_array_tot = np.vstack(tuplex)\n",
    "\n",
    "        \n",
    "#calculate adjusted p-values for all values\n",
    "\n",
    "p_array_tot_corrected = np.copy(p_array_tot)\n",
    "\n",
    "pHD = p_array_tot[:,10] #p values between depressed and healthy\n",
    "pH_HF = p_array_tot[:,11]\n",
    "pH_LF = p_array_tot[:,12]\n",
    "pD_HF =p_array_tot[:,13]\n",
    "pD_LF =p_array_tot[:,14]\n",
    "pHF_LF=p_array_tot[:,15]\n",
    "\n",
    "pHD = pHD.reshape(378,1)\n",
    "pH_HF = pH_HF.reshape(378,1)\n",
    "pH_LF = pH_LF.reshape(378,1)\n",
    "pD_HF = pD_HF.reshape(378,1)\n",
    "pD_LF= pD_LF.reshape(378,1)\n",
    "pHF_LF= pHF_LF.reshape(378,1)\n",
    "\n",
    "p_adjust_H_D = stats2.p_adjust(FloatVector(pHD), method = 'holm')\n",
    "p_adjust_H_HF = stats2.p_adjust(FloatVector(pH_HF), method = 'holm')\n",
    "p_adjust_H_LF = stats2.p_adjust(FloatVector(pH_LF), method = 'holm')\n",
    "p_adjust_D_HF = stats2.p_adjust(FloatVector(pD_HF), method = 'holm')\n",
    "p_adjust_D_LF = stats2.p_adjust(FloatVector(pD_LF), method = 'holm')\n",
    "p_adjust_LH_HF = stats2.p_adjust(FloatVector(pHF_LF), method = 'holm')    \n",
    "        \n",
    "p_array_tot_corrected[:,10] = p_adjust_H_D \n",
    "p_array_tot_corrected[:,11] =p_adjust_H_HF\n",
    "p_array_tot_corrected[:,12] = p_adjust_H_LF\n",
    "p_array_tot_corrected[:,13] = p_adjust_D_HF\n",
    "p_array_tot_corrected[:,14] = p_adjust_D_LF\n",
    "p_array_tot_corrected[:,15] =p_adjust_LH_HF   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"ok\")     \n",
    "file_name = mydir + \"/sign_coherence_uncorrected_alfa_8.csv\"\n",
    "outcome = pd.DataFrame.from_records(sign_array_tot)\n",
    "outcome.columns = [\"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"p HD\",\n",
    "                  \"p H_LF\", \"p H_HF\",\"p D_LF\", \"p D_HF\",'p_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                  \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF']\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)\n",
    "        \n",
    "tuple = (p_array_tot_corrected, p_array_tot)\n",
    "array_complete = np.hstack(tuple)\n",
    "\n",
    "file_name = mydir + \"/p-values_coherence_EF_corrected_alfa_8withT.csv\"\n",
    "outcome = pd.DataFrame.from_records(array_complete)\n",
    "outcome.columns = [\"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"padj HD\",\n",
    "                  \"padj H_LF\", \"padj H_HF\",\"padj D_LF\", \"padj D_HF\",'padj_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                   \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF',\n",
    "                  \"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"p HD\",\n",
    "                  \"p H_LF\", \"p H_HF\",\"p D_LF\", \"p D_HF\",'p_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                  \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF']\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "banner-digest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "#Calculate coherence over low alpha band (9-10Hz)\n",
    "\n",
    "c1 = np.repeat(\"\", 1)\n",
    "c2 = np.repeat(\"\",1)\n",
    "\n",
    "n_pairs = len(ROI_D)\n",
    "sig_count = False \n",
    "base = numpy.zeros(shape=(1,26)) \n",
    "#ROI1, ROI2, mean (4 times), sd (4 times), p value (H_D, H_HF, H_LF, D_HF, D_LF, HF_LF)\n",
    "sign_array = np.column_stack([c1, c2, base])\n",
    "sign_array_tot= np.column_stack([c1, c2, base])\n",
    "\n",
    "p_array = np.column_stack([c1, c2,base])\n",
    "p_array_tot= np.column_stack([c1, c2, base])\n",
    "\n",
    "Depr = Depr_9\n",
    "Health = Health_9\n",
    "HF = HF_9\n",
    "LF = LF_9\n",
    "\n",
    "for i in range(n_pairs):\n",
    "    data_dep = Depr[i]\n",
    "    data_health = Health[i]\n",
    "    data_HF = HF[i]\n",
    "    data_LF = LF[i]\n",
    "    \n",
    "    ROI1 = ROI_D[i][0]\n",
    "    ROI2 = ROI_D[i][1]\n",
    "    \n",
    "    #p_values\n",
    "    p_H_D = stats.ttest_ind(data_dep, data_health).pvalue\n",
    "    p_H_LF = stats.ttest_ind(data_LF, data_health).pvalue\n",
    "    p_H_HF = stats.ttest_ind(data_HF, data_health).pvalue\n",
    "    p_D_LF = stats.ttest_ind(data_dep, data_LF).pvalue\n",
    "    p_D_HF = stats.ttest_ind(data_dep, data_HF).pvalue\n",
    "    p_HF_LF = stats.ttest_ind(data_LF, data_HF).pvalue\n",
    "    \n",
    "    #t_stats\n",
    "    t_H_D = stats.ttest_ind(data_dep, data_health).statistic\n",
    "    t_H_LF = stats.ttest_ind(data_LF, data_health).statistic\n",
    "    t_H_HF = stats.ttest_ind(data_HF, data_health).statistic\n",
    "    t_D_LF = stats.ttest_ind(data_dep, data_LF).statistic\n",
    "    t_D_HF = stats.ttest_ind(data_dep, data_HF).statistic\n",
    "    t_HF_LF = stats.ttest_ind(data_LF, data_HF).statistic\n",
    "    \n",
    "    #Effect sizes\n",
    "    EF_H_D = EFsize(data_dep, data_health)\n",
    "    EF_H_LF = EFsize(data_LF, data_health)\n",
    "    EF_H_HF = EFsize(data_HF, data_health)\n",
    "    EF_D_LF = EFsize(data_dep, data_LF)\n",
    "    EF_D_HF = EFsize(data_dep, data_HF)\n",
    "    EF_HF_LF = EFsize(data_LF, data_HF)\n",
    "    \n",
    "    #make general p_value output (for all comparisons)\n",
    "    p_array[0][0] = str(ROI1)\n",
    "    p_array[0][1] = str(ROI2)\n",
    "    p_array[0][2] = mean(data_dep)\n",
    "    p_array[0][3] = mean(data_health)\n",
    "    p_array[0][4] = mean(data_HF)\n",
    "    p_array[0][5] = mean(data_LF)\n",
    "    p_array[0][6] = std(data_dep)\n",
    "    p_array[0][7] = std(data_health)\n",
    "    p_array[0][8] = std(data_HF)\n",
    "    p_array[0][9] = std(data_LF)\n",
    "    p_array[0][10] = p_H_D\n",
    "    p_array[0][11] = p_H_LF\n",
    "    p_array[0][12] = p_H_HF\n",
    "    p_array[0][13] = p_D_LF\n",
    "    p_array[0][14] = p_D_HF\n",
    "    p_array[0][15] = p_HF_LF\n",
    "    p_array[0][16] = EF_H_D\n",
    "    p_array[0][17] = EF_H_LF\n",
    "    p_array[0][18] = EF_H_HF\n",
    "    p_array[0][19] = EF_D_LF\n",
    "    p_array[0][20] = EF_D_HF\n",
    "    p_array[0][21] = EF_HF_LF\n",
    "    p_array[0][22] = t_H_D\n",
    "    p_array[0][23] = t_H_LF\n",
    "    p_array[0][24] = t_H_HF\n",
    "    p_array[0][25] = t_D_LF\n",
    "    p_array[0][26] = t_D_HF\n",
    "    p_array[0][27] = t_HF_LF\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #if any of p-values is significant: store these regions and all p-values corresponding in the significant matrix\n",
    "    if p_H_D <= 0.05 or p_H_LF <= 0.05 or p_H_HF <= 0.05 or p_D_LF <= 0.05 or p_D_HF <= 0.05 or p_HF_LF <= 0.05:\n",
    "        sign_array[0][0] = str(ROI1)\n",
    "        sign_array[0][1] = str(ROI2)\n",
    "        sign_array[0][2] = mean(data_dep)\n",
    "        sign_array[0][3] = mean(data_health)\n",
    "        sign_array[0][4] = mean(data_HF)\n",
    "        sign_array[0][5] = mean(data_LF)\n",
    "        sign_array[0][6] = std(data_dep)\n",
    "        sign_array[0][7] = std(data_health)\n",
    "        sign_array[0][8] = std(data_HF)\n",
    "        sign_array[0][9] = std(data_LF)\n",
    "        sign_array[0][10] = p_H_D\n",
    "        sign_array[0][11] = p_H_LF\n",
    "        sign_array[0][12] = p_H_HF\n",
    "        sign_array[0][13] = p_D_LF\n",
    "        sign_array[0][14] = p_D_HF\n",
    "        sign_array[0][15] = p_HF_LF\n",
    "        sign_array[0][16] = EF_H_D\n",
    "        sign_array[0][17] = EF_H_LF\n",
    "        sign_array[0][18] = EF_H_HF\n",
    "        sign_array[0][19] = EF_D_LF\n",
    "        sign_array[0][20] = EF_D_HF\n",
    "        sign_array[0][21] = EF_HF_LF\n",
    "        sign_array[0][22] = t_H_D\n",
    "        sign_array[0][23] = t_H_LF\n",
    "        sign_array[0][24] = t_H_HF\n",
    "        sign_array[0][25] = t_D_LF\n",
    "        sign_array[0][26] = t_D_HF\n",
    "        sign_array[0][27] = t_HF_LF\n",
    "        \n",
    "        if sig_count == False :\n",
    "            sign_array_tot = sign_array\n",
    "            sig_count = True \n",
    "        else:\n",
    "            tupley = (sign_array_tot, sign_array)\n",
    "            sign_array_tot = np.vstack(tupley)\n",
    " \n",
    "    \n",
    "    if i == 0:\n",
    "        p_array_tot = p_array\n",
    "    else:\n",
    "        tuplex = (p_array_tot, p_array)\n",
    "        p_array_tot = np.vstack(tuplex)\n",
    "\n",
    "        \n",
    "#calculate adjusted p-values for all values\n",
    "\n",
    "p_array_tot_corrected = np.copy(p_array_tot)\n",
    "\n",
    "pHD = p_array_tot[:,10] #p values between depressed and healthy\n",
    "pH_HF = p_array_tot[:,11]\n",
    "pH_LF = p_array_tot[:,12]\n",
    "pD_HF =p_array_tot[:,13]\n",
    "pD_LF =p_array_tot[:,14]\n",
    "pHF_LF=p_array_tot[:,15]\n",
    "\n",
    "pHD = pHD.reshape(378,1)\n",
    "pH_HF = pH_HF.reshape(378,1)\n",
    "pH_LF = pH_LF.reshape(378,1)\n",
    "pD_HF = pD_HF.reshape(378,1)\n",
    "pD_LF= pD_LF.reshape(378,1)\n",
    "pHF_LF= pHF_LF.reshape(378,1)\n",
    "\n",
    "p_adjust_H_D = stats2.p_adjust(FloatVector(pHD), method = 'holm')\n",
    "p_adjust_H_HF = stats2.p_adjust(FloatVector(pH_HF), method = 'holm')\n",
    "p_adjust_H_LF = stats2.p_adjust(FloatVector(pH_LF), method = 'holm')\n",
    "p_adjust_D_HF = stats2.p_adjust(FloatVector(pD_HF), method = 'holm')\n",
    "p_adjust_D_LF = stats2.p_adjust(FloatVector(pD_LF), method = 'holm')\n",
    "p_adjust_LH_HF = stats2.p_adjust(FloatVector(pHF_LF), method = 'holm')    \n",
    "        \n",
    "p_array_tot_corrected[:,10] = p_adjust_H_D \n",
    "p_array_tot_corrected[:,11] =p_adjust_H_HF\n",
    "p_array_tot_corrected[:,12] = p_adjust_H_LF\n",
    "p_array_tot_corrected[:,13] = p_adjust_D_HF\n",
    "p_array_tot_corrected[:,14] = p_adjust_D_LF\n",
    "p_array_tot_corrected[:,15] =p_adjust_LH_HF   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"ok\")     \n",
    "file_name = mydir + \"/sign_coherence_uncorrected_alfa_9.csv\"\n",
    "outcome = pd.DataFrame.from_records(sign_array_tot)\n",
    "outcome.columns = [\"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"p HD\",\n",
    "                  \"p H_LF\", \"p H_HF\",\"p D_LF\", \"p D_HF\",'p_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                  \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF']\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)\n",
    "        \n",
    "tuple = (p_array_tot_corrected, p_array_tot)\n",
    "array_complete = np.hstack(tuple)\n",
    "\n",
    "file_name = mydir + \"/p-values_coherence_EF_corrected_alfa_9withT.csv\"\n",
    "outcome = pd.DataFrame.from_records(array_complete)\n",
    "outcome.columns = [\"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"padj HD\",\n",
    "                  \"padj H_LF\", \"padj H_HF\",\"padj D_LF\", \"padj D_HF\",'padj_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                   \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF',\n",
    "                  \"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"p HD\",\n",
    "                  \"p H_LF\", \"p H_HF\",\"p D_LF\", \"p D_HF\",'p_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                  \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF']\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mexican-pakistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "#Calculate coherence over middle alpha band (10_11Hz)\n",
    "\n",
    "c1 = np.repeat(\"\", 1)\n",
    "c2 = np.repeat(\"\",1)\n",
    "\n",
    "n_pairs = len(ROI_D)\n",
    "sig_count = False \n",
    "base = numpy.zeros(shape=(1,26)) \n",
    "#ROI1, ROI2, mean (4 times), sd (4 times), p value (H_D, H_HF, H_LF, D_HF, D_LF, HF_LF)\n",
    "sign_array = np.column_stack([c1, c2, base])\n",
    "sign_array_tot= np.column_stack([c1, c2, base])\n",
    "\n",
    "p_array = np.column_stack([c1, c2,base])\n",
    "p_array_tot= np.column_stack([c1, c2, base])\n",
    "\n",
    "Depr = Depr_10\n",
    "Health = Health_10\n",
    "HF = HF_10\n",
    "LF = LF_10\n",
    "\n",
    "for i in range(n_pairs):\n",
    "    data_dep = Depr[i]\n",
    "    data_health = Health[i]\n",
    "    data_HF = HF[i]\n",
    "    data_LF = LF[i]\n",
    "    \n",
    "    ROI1 = ROI_D[i][0]\n",
    "    ROI2 = ROI_D[i][1]\n",
    "    \n",
    "    #p_values\n",
    "    p_H_D = stats.ttest_ind(data_dep, data_health).pvalue\n",
    "    p_H_LF = stats.ttest_ind(data_LF, data_health).pvalue\n",
    "    p_H_HF = stats.ttest_ind(data_HF, data_health).pvalue\n",
    "    p_D_LF = stats.ttest_ind(data_dep, data_LF).pvalue\n",
    "    p_D_HF = stats.ttest_ind(data_dep, data_HF).pvalue\n",
    "    p_HF_LF = stats.ttest_ind(data_LF, data_HF).pvalue\n",
    "    \n",
    "    #t_stats\n",
    "    t_H_D = stats.ttest_ind(data_dep, data_health).statistic\n",
    "    t_H_LF = stats.ttest_ind(data_LF, data_health).statistic\n",
    "    t_H_HF = stats.ttest_ind(data_HF, data_health).statistic\n",
    "    t_D_LF = stats.ttest_ind(data_dep, data_LF).statistic\n",
    "    t_D_HF = stats.ttest_ind(data_dep, data_HF).statistic\n",
    "    t_HF_LF = stats.ttest_ind(data_LF, data_HF).statistic\n",
    "    \n",
    "    #Effect sizes\n",
    "    EF_H_D = EFsize(data_dep, data_health)\n",
    "    EF_H_LF = EFsize(data_LF, data_health)\n",
    "    EF_H_HF = EFsize(data_HF, data_health)\n",
    "    EF_D_LF = EFsize(data_dep, data_LF)\n",
    "    EF_D_HF = EFsize(data_dep, data_HF)\n",
    "    EF_HF_LF = EFsize(data_LF, data_HF)\n",
    "    \n",
    "    #make general p_value output (for all comparisons)\n",
    "    p_array[0][0] = str(ROI1)\n",
    "    p_array[0][1] = str(ROI2)\n",
    "    p_array[0][2] = mean(data_dep)\n",
    "    p_array[0][3] = mean(data_health)\n",
    "    p_array[0][4] = mean(data_HF)\n",
    "    p_array[0][5] = mean(data_LF)\n",
    "    p_array[0][6] = std(data_dep)\n",
    "    p_array[0][7] = std(data_health)\n",
    "    p_array[0][8] = std(data_HF)\n",
    "    p_array[0][9] = std(data_LF)\n",
    "    p_array[0][10] = p_H_D\n",
    "    p_array[0][11] = p_H_LF\n",
    "    p_array[0][12] = p_H_HF\n",
    "    p_array[0][13] = p_D_LF\n",
    "    p_array[0][14] = p_D_HF\n",
    "    p_array[0][15] = p_HF_LF\n",
    "    p_array[0][16] = EF_H_D\n",
    "    p_array[0][17] = EF_H_LF\n",
    "    p_array[0][18] = EF_H_HF\n",
    "    p_array[0][19] = EF_D_LF\n",
    "    p_array[0][20] = EF_D_HF\n",
    "    p_array[0][21] = EF_HF_LF\n",
    "    p_array[0][22] = t_H_D\n",
    "    p_array[0][23] = t_H_LF\n",
    "    p_array[0][24] = t_H_HF\n",
    "    p_array[0][25] = t_D_LF\n",
    "    p_array[0][26] = t_D_HF\n",
    "    p_array[0][27] = t_HF_LF\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #if any of p-values is significant: store these regions and all p-values corresponding in the significant matrix\n",
    "    if p_H_D <= 0.05 or p_H_LF <= 0.05 or p_H_HF <= 0.05 or p_D_LF <= 0.05 or p_D_HF <= 0.05 or p_HF_LF <= 0.05:\n",
    "        sign_array[0][0] = str(ROI1)\n",
    "        sign_array[0][1] = str(ROI2)\n",
    "        sign_array[0][2] = mean(data_dep)\n",
    "        sign_array[0][3] = mean(data_health)\n",
    "        sign_array[0][4] = mean(data_HF)\n",
    "        sign_array[0][5] = mean(data_LF)\n",
    "        sign_array[0][6] = std(data_dep)\n",
    "        sign_array[0][7] = std(data_health)\n",
    "        sign_array[0][8] = std(data_HF)\n",
    "        sign_array[0][9] = std(data_LF)\n",
    "        sign_array[0][10] = p_H_D\n",
    "        sign_array[0][11] = p_H_LF\n",
    "        sign_array[0][12] = p_H_HF\n",
    "        sign_array[0][13] = p_D_LF\n",
    "        sign_array[0][14] = p_D_HF\n",
    "        sign_array[0][15] = p_HF_LF\n",
    "        sign_array[0][16] = EF_H_D\n",
    "        sign_array[0][17] = EF_H_LF\n",
    "        sign_array[0][18] = EF_H_HF\n",
    "        sign_array[0][19] = EF_D_LF\n",
    "        sign_array[0][20] = EF_D_HF\n",
    "        sign_array[0][21] = EF_HF_LF\n",
    "        sign_array[0][22] = t_H_D\n",
    "        sign_array[0][23] = t_H_LF\n",
    "        sign_array[0][24] = t_H_HF\n",
    "        sign_array[0][25] = t_D_LF\n",
    "        sign_array[0][26] = t_D_HF\n",
    "        sign_array[0][27] = t_HF_LF\n",
    "        \n",
    "        if sig_count == False :\n",
    "            sign_array_tot = sign_array\n",
    "            sig_count = True \n",
    "        else:\n",
    "            tupley = (sign_array_tot, sign_array)\n",
    "            sign_array_tot = np.vstack(tupley)\n",
    " \n",
    "    \n",
    "    if i == 0:\n",
    "        p_array_tot = p_array\n",
    "    else:\n",
    "        tuplex = (p_array_tot, p_array)\n",
    "        p_array_tot = np.vstack(tuplex)\n",
    "\n",
    "        \n",
    "#calculate adjusted p-values for all values\n",
    "\n",
    "p_array_tot_corrected = np.copy(p_array_tot)\n",
    "\n",
    "pHD = p_array_tot[:,10] #p values between depressed and healthy\n",
    "pH_HF = p_array_tot[:,11]\n",
    "pH_LF = p_array_tot[:,12]\n",
    "pD_HF =p_array_tot[:,13]\n",
    "pD_LF =p_array_tot[:,14]\n",
    "pHF_LF=p_array_tot[:,15]\n",
    "\n",
    "pHD = pHD.reshape(378,1)\n",
    "pH_HF = pH_HF.reshape(378,1)\n",
    "pH_LF = pH_LF.reshape(378,1)\n",
    "pD_HF = pD_HF.reshape(378,1)\n",
    "pD_LF= pD_LF.reshape(378,1)\n",
    "pHF_LF= pHF_LF.reshape(378,1)\n",
    "\n",
    "p_adjust_H_D = stats2.p_adjust(FloatVector(pHD), method = 'holm')\n",
    "p_adjust_H_HF = stats2.p_adjust(FloatVector(pH_HF), method = 'holm')\n",
    "p_adjust_H_LF = stats2.p_adjust(FloatVector(pH_LF), method = 'holm')\n",
    "p_adjust_D_HF = stats2.p_adjust(FloatVector(pD_HF), method = 'holm')\n",
    "p_adjust_D_LF = stats2.p_adjust(FloatVector(pD_LF), method = 'holm')\n",
    "p_adjust_LH_HF = stats2.p_adjust(FloatVector(pHF_LF), method = 'holm')    \n",
    "        \n",
    "p_array_tot_corrected[:,10] = p_adjust_H_D \n",
    "p_array_tot_corrected[:,11] =p_adjust_H_HF\n",
    "p_array_tot_corrected[:,12] = p_adjust_H_LF\n",
    "p_array_tot_corrected[:,13] = p_adjust_D_HF\n",
    "p_array_tot_corrected[:,14] = p_adjust_D_LF\n",
    "p_array_tot_corrected[:,15] =p_adjust_LH_HF   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"ok\")     \n",
    "file_name = mydir + \"/sign_coherence_uncorrected_alfa_10.csv\"\n",
    "outcome = pd.DataFrame.from_records(sign_array_tot)\n",
    "outcome.columns = [\"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"p HD\",\n",
    "                  \"p H_LF\", \"p H_HF\",\"p D_LF\", \"p D_HF\",'p_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                  \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF']\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)\n",
    "        \n",
    "tuple = (p_array_tot_corrected, p_array_tot)\n",
    "array_complete = np.hstack(tuple)\n",
    "\n",
    "file_name = mydir + \"/p-values_coherence_EF_corrected_alfa_10withT.csv\"\n",
    "outcome = pd.DataFrame.from_records(array_complete)\n",
    "outcome.columns = [\"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"padj HD\",\n",
    "                  \"padj H_LF\", \"padj H_HF\",\"padj D_LF\", \"padj D_HF\",'padj_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                   \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF',\n",
    "                  \"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"p HD\",\n",
    "                  \"p H_LF\", \"p H_HF\",\"p D_LF\", \"p D_HF\",'p_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                  \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF']\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "expected-evanescence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "#Calculate coherence over high alpha band (11-12Hz)\n",
    "\n",
    "c1 = np.repeat(\"\", 1)\n",
    "c2 = np.repeat(\"\",1)\n",
    "\n",
    "n_pairs = len(ROI_D)\n",
    "sig_count = False \n",
    "base = numpy.zeros(shape=(1,26)) \n",
    "#ROI1, ROI2, mean (4 times), sd (4 times), p value (H_D, H_HF, H_LF, D_HF, D_LF, HF_LF)\n",
    "sign_array = np.column_stack([c1, c2, base])\n",
    "sign_array_tot= np.column_stack([c1, c2, base])\n",
    "\n",
    "p_array = np.column_stack([c1, c2,base])\n",
    "p_array_tot= np.column_stack([c1, c2, base])\n",
    "\n",
    "Depr = Depr_11\n",
    "Health = Health_11\n",
    "HF = HF_11\n",
    "LF = LF_11\n",
    "\n",
    "for i in range(n_pairs):\n",
    "    data_dep = Depr[i]\n",
    "    data_health = Health[i]\n",
    "    data_HF = HF[i]\n",
    "    data_LF = LF[i]\n",
    "    \n",
    "    ROI1 = ROI_D[i][0]\n",
    "    ROI2 = ROI_D[i][1]\n",
    "    \n",
    "    #p_values\n",
    "    p_H_D = stats.ttest_ind(data_dep, data_health).pvalue\n",
    "    p_H_LF = stats.ttest_ind(data_LF, data_health).pvalue\n",
    "    p_H_HF = stats.ttest_ind(data_HF, data_health).pvalue\n",
    "    p_D_LF = stats.ttest_ind(data_dep, data_LF).pvalue\n",
    "    p_D_HF = stats.ttest_ind(data_dep, data_HF).pvalue\n",
    "    p_HF_LF = stats.ttest_ind(data_LF, data_HF).pvalue\n",
    "    \n",
    "    #t_stats\n",
    "    t_H_D = stats.ttest_ind(data_dep, data_health).statistic\n",
    "    t_H_LF = stats.ttest_ind(data_LF, data_health).statistic\n",
    "    t_H_HF = stats.ttest_ind(data_HF, data_health).statistic\n",
    "    t_D_LF = stats.ttest_ind(data_dep, data_LF).statistic\n",
    "    t_D_HF = stats.ttest_ind(data_dep, data_HF).statistic\n",
    "    t_HF_LF = stats.ttest_ind(data_LF, data_HF).statistic\n",
    "    \n",
    "    #Effect sizes\n",
    "    EF_H_D = EFsize(data_dep, data_health)\n",
    "    EF_H_LF = EFsize(data_LF, data_health)\n",
    "    EF_H_HF = EFsize(data_HF, data_health)\n",
    "    EF_D_LF = EFsize(data_dep, data_LF)\n",
    "    EF_D_HF = EFsize(data_dep, data_HF)\n",
    "    EF_HF_LF = EFsize(data_LF, data_HF)\n",
    "    \n",
    "    #make general p_value output (for all comparisons)\n",
    "    p_array[0][0] = str(ROI1)\n",
    "    p_array[0][1] = str(ROI2)\n",
    "    p_array[0][2] = mean(data_dep)\n",
    "    p_array[0][3] = mean(data_health)\n",
    "    p_array[0][4] = mean(data_HF)\n",
    "    p_array[0][5] = mean(data_LF)\n",
    "    p_array[0][6] = std(data_dep)\n",
    "    p_array[0][7] = std(data_health)\n",
    "    p_array[0][8] = std(data_HF)\n",
    "    p_array[0][9] = std(data_LF)\n",
    "    p_array[0][10] = p_H_D\n",
    "    p_array[0][11] = p_H_LF\n",
    "    p_array[0][12] = p_H_HF\n",
    "    p_array[0][13] = p_D_LF\n",
    "    p_array[0][14] = p_D_HF\n",
    "    p_array[0][15] = p_HF_LF\n",
    "    p_array[0][16] = EF_H_D\n",
    "    p_array[0][17] = EF_H_LF\n",
    "    p_array[0][18] = EF_H_HF\n",
    "    p_array[0][19] = EF_D_LF\n",
    "    p_array[0][20] = EF_D_HF\n",
    "    p_array[0][21] = EF_HF_LF\n",
    "    p_array[0][22] = t_H_D\n",
    "    p_array[0][23] = t_H_LF\n",
    "    p_array[0][24] = t_H_HF\n",
    "    p_array[0][25] = t_D_LF\n",
    "    p_array[0][26] = t_D_HF\n",
    "    p_array[0][27] = t_HF_LF\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #if any of p-values is significant: store these regions and all p-values corresponding in the significant matrix\n",
    "    if p_H_D <= 0.05 or p_H_LF <= 0.05 or p_H_HF <= 0.05 or p_D_LF <= 0.05 or p_D_HF <= 0.05 or p_HF_LF <= 0.05:\n",
    "        sign_array[0][0] = str(ROI1)\n",
    "        sign_array[0][1] = str(ROI2)\n",
    "        sign_array[0][2] = mean(data_dep)\n",
    "        sign_array[0][3] = mean(data_health)\n",
    "        sign_array[0][4] = mean(data_HF)\n",
    "        sign_array[0][5] = mean(data_LF)\n",
    "        sign_array[0][6] = std(data_dep)\n",
    "        sign_array[0][7] = std(data_health)\n",
    "        sign_array[0][8] = std(data_HF)\n",
    "        sign_array[0][9] = std(data_LF)\n",
    "        sign_array[0][10] = p_H_D\n",
    "        sign_array[0][11] = p_H_LF\n",
    "        sign_array[0][12] = p_H_HF\n",
    "        sign_array[0][13] = p_D_LF\n",
    "        sign_array[0][14] = p_D_HF\n",
    "        sign_array[0][15] = p_HF_LF\n",
    "        sign_array[0][16] = EF_H_D\n",
    "        sign_array[0][17] = EF_H_LF\n",
    "        sign_array[0][18] = EF_H_HF\n",
    "        sign_array[0][19] = EF_D_LF\n",
    "        sign_array[0][20] = EF_D_HF\n",
    "        sign_array[0][21] = EF_HF_LF\n",
    "        sign_array[0][22] = t_H_D\n",
    "        sign_array[0][23] = t_H_LF\n",
    "        sign_array[0][24] = t_H_HF\n",
    "        sign_array[0][25] = t_D_LF\n",
    "        sign_array[0][26] = t_D_HF\n",
    "        sign_array[0][27] = t_HF_LF\n",
    "        \n",
    "        if sig_count == False :\n",
    "            sign_array_tot = sign_array\n",
    "            sig_count = True \n",
    "        else:\n",
    "            tupley = (sign_array_tot, sign_array)\n",
    "            sign_array_tot = np.vstack(tupley)\n",
    " \n",
    "    \n",
    "    if i == 0:\n",
    "        p_array_tot = p_array\n",
    "    else:\n",
    "        tuplex = (p_array_tot, p_array)\n",
    "        p_array_tot = np.vstack(tuplex)\n",
    "\n",
    "        \n",
    "#calculate adjusted p-values for all values\n",
    "\n",
    "p_array_tot_corrected = np.copy(p_array_tot)\n",
    "\n",
    "pHD = p_array_tot[:,10] #p values between depressed and healthy\n",
    "pH_HF = p_array_tot[:,11]\n",
    "pH_LF = p_array_tot[:,12]\n",
    "pD_HF =p_array_tot[:,13]\n",
    "pD_LF =p_array_tot[:,14]\n",
    "pHF_LF=p_array_tot[:,15]\n",
    "\n",
    "pHD = pHD.reshape(378,1)\n",
    "pH_HF = pH_HF.reshape(378,1)\n",
    "pH_LF = pH_LF.reshape(378,1)\n",
    "pD_HF = pD_HF.reshape(378,1)\n",
    "pD_LF= pD_LF.reshape(378,1)\n",
    "pHF_LF= pHF_LF.reshape(378,1)\n",
    "\n",
    "p_adjust_H_D = stats2.p_adjust(FloatVector(pHD), method = 'holm')\n",
    "p_adjust_H_HF = stats2.p_adjust(FloatVector(pH_HF), method = 'holm')\n",
    "p_adjust_H_LF = stats2.p_adjust(FloatVector(pH_LF), method = 'holm')\n",
    "p_adjust_D_HF = stats2.p_adjust(FloatVector(pD_HF), method = 'holm')\n",
    "p_adjust_D_LF = stats2.p_adjust(FloatVector(pD_LF), method = 'holm')\n",
    "p_adjust_LH_HF = stats2.p_adjust(FloatVector(pHF_LF), method = 'holm')    \n",
    "        \n",
    "p_array_tot_corrected[:,10] = p_adjust_H_D \n",
    "p_array_tot_corrected[:,11] =p_adjust_H_HF\n",
    "p_array_tot_corrected[:,12] = p_adjust_H_LF\n",
    "p_array_tot_corrected[:,13] = p_adjust_D_HF\n",
    "p_array_tot_corrected[:,14] = p_adjust_D_LF\n",
    "p_array_tot_corrected[:,15] =p_adjust_LH_HF   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"ok\")     \n",
    "file_name = mydir + \"/sign_coherence_uncorrected_alfa_11.csv\"\n",
    "outcome = pd.DataFrame.from_records(sign_array_tot)\n",
    "outcome.columns = [\"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"p HD\",\n",
    "                  \"p H_LF\", \"p H_HF\",\"p D_LF\", \"p D_HF\",'p_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                  \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF']\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)\n",
    "        \n",
    "tuple = (p_array_tot_corrected, p_array_tot)\n",
    "array_complete = np.hstack(tuple)\n",
    "\n",
    "file_name = mydir + \"/p-values_coherence_EF_corrected_alfa_11withT.csv\"\n",
    "outcome = pd.DataFrame.from_records(array_complete)\n",
    "outcome.columns = [\"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"padj HD\",\n",
    "                  \"padj H_LF\", \"padj H_HF\",\"padj D_LF\", \"padj D_HF\",'padj_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                   \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF',\n",
    "                  \"ROI1\", \"ROI2\", \"meanDEP\", \"meanHEALTH\", \"meanHF\", \"meanLF\",\"stdDEP\", \"stdHEALTH\",\"stdHF\",\"stdLF\",\"p HD\",\n",
    "                  \"p H_LF\", \"p H_HF\",\"p D_LF\", \"p D_HF\",'p_HF_LF',\"EF HD\",\n",
    "                  \"EF H_LF\", \"EF H_HF\",\"EF D_LF\", \"EF D_HF\",'EF_HF_LF',\n",
    "                  \"t HD\",\"t H_LF\", \"t H_HF\",\"t D_LF\", \"t D_HF\",'t_HF_LF']\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-correspondence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "thesisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
